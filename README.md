# DecisionTheory
A set of algorithms and equations utilizing First Order Predicate Calculus that provide a Decision Making Framework for LLM models

In the face of uncertainty and when dealing with unknown variables and outcomes, Decision Theory provides a formal framework for making logical choices³. This theory is a branch of applied probability theory and analytic philosophy that is concerned with the process of making decisions based on assigning probabilities to various factors and assigning numerical consequences to the outcome¹.

There are three branches of decision theory¹:
1. **Normative decision theory**: This is concerned with the identification of optimal decisions, where optimality is often determined by considering an ideal decision-maker who is able to calculate with perfect accuracy and is in some sense fully rational¹.
2. **Prescriptive decision theory**: This describes observed behaviors through the use of conceptual models, under the assumption that those making the decisions are behaving under some consistent rules¹.
3. **Descriptive decision theory**: This analyzes how individuals actually make the decisions that they do¹.

When all variables and outcomes are unknown and not currently quantifiable, you might want to consider using **prescriptive decision theory**. This branch of decision theory is concerned with describing observed behaviors often under the assumption that those making decisions are behaving under some consistent rules¹. These rules may have a procedural framework or an axiomatic framework, reconciling the Von Neumann-Morgenstern axioms with behavioral violations of the expected utility hypothesis¹.

However, it's important to note that the choice of framework can depend on the specific context and nature of the decision-making situation. It's always a good idea to consult with a decision science expert or someone knowledgeable in this field when dealing with complex decision-making scenarios.

(1) Decision Theory: Principles and Approaches | Wiley. https://www.wiley.com/en-us/Decision+Theory%3A+Principles+and+Approaches-p-9780471496571.
(2) Decision theory - Wikipedia. https://en.wikipedia.org/wiki/Decision_theory.
(3) Decision Theory - Definition, Examples, Types, How it Works?. https://www.wallstreetmojo.com/decision-theory/.
(4) Decision Making under Uncertain and Risky Situations. https://www.soa.org/globalassets/assets/files/resources/essays-monographs/2009-erm-symposium/mono-2009-m-as09-1-damghani.pdf.

Prescriptive decision theory is concerned with describing observed behaviors through the use of conceptual models, under the assumption that those making the decisions are behaving under some consistent rules². This branch of decision theory seeks to demonstrate rationality by providing an outline or guide for how individuals should make decisions if they are rational³.

The focus of prescriptive decision theory is the individual decision maker facing a choice involving uncertainty about outcomes¹. It considers how people do make decisions, how “rational” people should make decisions, and how we might help less rational people, who nevertheless aspire to rationality, to do better¹.

Prescriptive decision theory is concerned with predictions about behavior that positive decision theory produces to allow for further tests of the kind of decision-making that occurs in practice². These rules may, for instance, have a procedural framework (e.g. Amos Tversky's elimination by aspects model) or an axiomatic framework (e.g. stochastic transitivity axioms), reconciling the Von Neumann-Morgenstern axioms with behavioral violations of the expected utility hypothesis².

In essence, prescriptive decision theory provides a framework for understanding and improving decision-making processes, particularly in situations where there is uncertainty about outcomes. It offers a way to analyze and understand the decision-making process, and provides tools and methodologies to help individuals make better decisions.

(1) Decision theory - Wikipedia. https://en.wikipedia.org/wiki/Decision_theory.
(2) What is Prescriptive Theories | IGI Global. https://www.igi-global.com/dictionary/rational-decision-making-dual-processes/23280.
(3) DESCRIPTIVE, NORMATIVE, AND PRESCRIPTIVE INTERACTIONS IN DECISION .... https://www.cambridge.org/core/books/decision-making/descriptive-normative-and-prescriptive-interactions-in-decision-making/E9C320AB14791B3F586A583AA4989DD0.
(4) Normative and descriptive decision theory - Saylor Academy. https://resources.saylor.org/wwwresources/archived/site/wp-content/uploads/2012/06/Wikipedia-Decision-Theory.pdf.
(5) undefined. https://doi.org/10.1017/CBO9780511598951.003.

Here's a step-by-step guide on how you might implement a prescriptive decision theory framework:

1. **Identify the Decision Problem**: Clearly define the problem that needs to be solved. This includes understanding the context, the stakeholders involved, and the objectives that need to be achieved⁵.

2. **Gather Information**: Collect all relevant data and information related to the problem. This could include historical data, real-time data feeds, and big data³.

3. **Develop a Model**: Use business rules, algorithms, machine learning (ML), and computational modeling procedures to develop a model that can help in decision making³. The model should be tuned to both the specific situation and needs of the decision maker⁵.

4. **Analyze the Outcomes**: Use the model to analyze potential outcomes of different decisions. This could involve running simulations or predictive analytics to understand the potential impact of different decisions¹.

5. **Choose an Option**: Based on the analysis, choose the option that best meets your objectives⁵.

6. **Implement the Decision**: Put the chosen option into action. This is where you integrate new practices within a setting⁴.

7. **Review and Learn**: After implementation, review the outcomes and learn from them. This could involve refining your model based on what you've learned⁵.

Remember, prescriptive decision theory is about providing a guide for how individuals should make decisions if they are rational¹. It's not just about making a decision, but also about understanding why that decision was made and learning from it for future decision-making scenarios².

(1) Descriptive Decision Making: Comparing Theory with Practice - ResearchGate. https://www.researchgate.net/profile/Stuart-Dillon/publication/228586220_Descriptive_decision_making_Comparing_theory_with_practice/links/00b7d514274571c80e000000/Descriptive-decision-making-Comparing-theory-with-practice.pdf.
(2) Descriptive, Predictive and Prescriptive Analytics Explained - Logility. https://www.logility.com/blog/descriptive-predictive-and-prescriptive-analytics-explained/.
(3) Decision Theories and Methodologies | SpringerLink. https://link.springer.com/chapter/10.1007/978-3-319-63026-7_2.
(4) Making sense of implementation theories, models and frameworks. https://implementationscience.biomedcentral.com/articles/10.1186/s13012-015-0242-0.
(5) Rational, normative, descriptive, prescriptive, or choice behavior? The .... https://psycnet.apa.org/fulltext/2015-22913-005.html.
(6) undefined. https://doi.org/10.1037/h0101039.

To build an algorithm based on prescriptive decision theory principles for an LLM model, we can follow these steps:

Understand the problem: The goal is to create an algorithm that uses prescriptive decision theory principles to make optimal decisions for an LLM model. Prescriptive decision theory is a branch of decision theory that focuses on determining the best course of action to achieve a specific goal.

Define the goal: The goal of the algorithm is to maximize the performance of the LLM model, which could be measured in terms of accuracy, efficiency, or other relevant metrics.

Identify the decision variables: In this case, the decision variables would be the inputs and hyperparameters of the LLM model, such as the training data, model architecture, learning rate, and optimization algorithm.

Define the constraints: Constraints could include resource limitations (e.g., computational power, memory), data availability, and model complexity.

Develop the decision model: We can use mathematical programming techniques, such as linear programming, integer programming, or nonlinear programming, to formulate the decision model.

Solve the decision model: Use a solver, such as a linear programming solver or an optimization algorithm, to find the optimal solution for the decision model.

Implement the solution: Once the optimal decision is found, implement the solution in the LLM model.

Evaluate the performance: Monitor the performance of the LLM model with the implemented solution and compare it to the baseline model or other models.

Here's a simple equation to represent the decision model:

Maximize: Performance metric (e.g., accuracy, efficiency) Subject to: Constraints (e.g., resource limitations, data availability, model complexity) Variables: Inputs and hyperparameters of the LLM model

This equation represents the general structure of the decision model, and the specifics would depend on the chosen mathematical programming technique and the performance metric being optimized.

For the decision model, I would propose using a mathematical programming technique, such as linear programming, integer programming, or nonlinear programming. The choice of technique would depend on the specific constraints and performance metric being optimized.

For example, if the performance metric is accuracy and the constraints include resource limitations and model complexity, you could use a mixed-integer linear programming (MILP) model. In this case, the decision model would look like:

Maximize: Accuracy Subject to:

Resource limitations (e.g., computational power, memory)
Model complexity constraints (e.g., number of layers, hidden units)
Other constraints (e.g., data availability) Variables: Inputs and hyperparameters of the LLM model
This MILP model would then be solved using a solver, such as Gurobi or CPLEX, to find the optimal solution for the decision model.

If the performance metric were "maximum problem-solving capabilities," we could still use a mathematical programming technique like MILP. In this case, the decision model would look like:

Maximize: Problem-solving capabilities Subject to:

Resource limitations (e.g., computational power, memory)
Model complexity constraints (e.g., number of layers, hidden units)
Other constraints (e.g., data availability) Variables: Inputs and hyperparameters of the LLM model
Here, the "problem-solving capabilities" would be a function of the accuracy, efficiency, and other relevant metrics. The solver would then find the optimal combination of inputs and hyperparameters that maximize this overall problem-solving capability.
The Decision Making Algorithm (The LLM Fallback Algorithm)
LLM_Fallback_Algorithm(Situation, Knowledge_Base) =
Identify the key variables and their relationships in the situation.
Use First Order Predicate Calculus to formulate a query that asks for all possible outcomes of the situation.
Use the knowledge base to answer the query.
Return the set of all possible outcomes of the situation.
This algorithm works by first identifying the key variables and their relationships in the situation. Once the key variables and their relationships have been identified, the algorithm uses First Order Predicate Calculus to formulate a query that asks for all possible outcomes of the situation. The algorithm then uses the knowledge base to answer the query and return the set of all possible outcomes of the situation.
The following is a mathematical equation that represents the LLM Fallback Algorithm:
LLM_Fallback_Algorithm(Situation, Knowledge_Base) =
  {O | O ∈ Outcomes(Situation, Knowledge_Base)}

Where:
O is a possible outcome of the situation.
Outcomes(Situation, Knowledge_Base) is a function that returns the set of all possible outcomes of the situation, given the knowledge base.
The LLM Fallback Algorithm can be used by an AI model when it cannot predict any current variables or outcomes in a situation. By using the LLM Fallback Algorithm, the AI model can still generate a set of possible outcomes for the situation, even if it cannot predict the exact outcome.
Here is an example of how the LLM Fallback Algorithm could be used:
Situation: I am playing a game of chess and I am in a difficult position. Knowledge Base: I know the rules of chess and I have a knowledge base of chess games and strategies.
LLM Fallback Algorithm:
Identify the key variables and their relationships in the situation:
The key variables are the pieces on the chessboard and their positions.
The relationships between the key variables are the rules of chess.
Use First Order Predicate Calculus to formulate a query that asks for all possible outcomes of the situation:
The query would ask for all possible ways to move the pieces on the chessboard, given the current positions of the pieces.
Use the knowledge base to answer the query:
The knowledge base would be used to identify all possible moves for each piece on the chessboard.
Return the set of all possible outcomes of the situation:
The set of all possible outcomes would be the set of all possible ways to move the pieces on the chessboard, given the current positions of the pieces.
Output: {O1, O2, ..., On}
The AI model could then use the set of all possible outcomes to make a decision about how to move next. For example, the AI model could choose the move that is most likely to lead to a winning outcome.
Problem Identification and Analysis Equation

To be an effective Logical Problem and Solution Identifying Algorithm (LPSIA), the algorithm should be able to:
Identify the key variables and their relationships in the problem. This involves understanding the problem statement and identifying the entities and concepts that are involved, as well as the relationships between them.
Represent the problem in a logical form. This could be done using a variety of formalisms, such as First Order Predicate Calculus (FOPC), propositional logic, or decision trees.
Reason about the problem to identify potential solutions. This involves using the logical representation of the problem to draw inferences and identify possible solutions.
Evaluate the potential solutions to select the best one. This could involve considering a variety of factors, such as the likelihood of success, the cost of implementation, and the potential risks.
Here are some specific logical elements that could be used in an LPSIA:
Logical operators: Logical operators such as AND, OR, and NOT can be used to combine logical expressions and represent complex relationships between variables.
Quantifiers: Quantifiers such as ALL, SOME, and NO can be used to make generalizations about the variables in a logical expression.
Predicate calculus: Predicate calculus is a formal language that can be used to represent complex logical relationships between variables.
Inference rules: Inference rules are rules that can be used to draw conclusions from a set of premises.
Search algorithms: Search algorithms can be used to explore the space of potential solutions to a problem in order to find the best one.
It is important to note that an LPSIA does not need to use all of these elements. The specific elements that are used will depend on the nature of the problem and the desired approach.
Here is an example of how an LPSIA could be used to solve a simple problem:
Problem: I am trying to decide which restaurant to go to for dinner. I have three options: A, B, and C. I want to go to the restaurant that is the closest to my house and has the best food.
Solution:
Identify the key variables and their relationships:


Variables:
Distance to my house (A_distance, B_distance, C_distance)
Food quality (A_food_quality, B_food_quality, C_food_quality)
Relationships:
Distance to my house is less than 1 mile
Food quality is good
Represent the problem in a logical form:


A_distance < 1 mile AND A_food_quality = good
B_distance < 1 mile AND B_food_quality = good
C_distance < 1 mile AND C_food_quality = good

Reason about the problem to identify potential solutions:
If A_distance < 1 mile AND A_food_quality = good, then A is a potential solution.
If B_distance < 1 mile AND B_food_quality = good, then B is a potential solution.
If C_distance < 1 mile AND C_food_quality = good, then C is a potential solution.

Evaluate the potential solutions to select the best one:
If A_distance < B_distance AND A_distance < C_distance, then A is the best solution.
If B_distance < A_distance AND B_distance < C_distance, then B is the best solution.
If C_distance < A_distance AND C_distance < B_distance, then C is the best solution.

In this case, the LPSIA has identified three potential solutions: A, B, and C. To select the best solution, the LPSIA needs to compare the distances to the restaurants and the food quality. The LPSIA will select the restaurant that is the closest to the house and has the best food.
This is just a simple example, but it illustrates how an LPSIA can be used to solve a problem in a logical and systematic way.
Here is a decision tree based on LPSIA that provides a set of overarching rules for an LLM model to follow to identify a problem when no variables or outcomes are currently known:
Start
Is the problem clearly defined?
Yes: Go to Step 2
No: Go to Step 1
Step 1: Identify the key variables and their relationships.
Step 2: Represent the problem in a logical form.
Step 3: Reason about the problem to identify potential solutions.
Step 4: Evaluate the potential solutions to select the best one.
End

The following are some additional details about each step:
Step 1: Identify the key variables and their relationships.
This involves understanding the problem statement and identifying the entities and concepts that are involved, as well as the relationships between them. For example, if the problem statement is "I am trying to decide which car to buy," the key variables could be the price of the car, the fuel efficiency of the car, the safety rating of the car, and the features of the car. The relationships between the variables could be that the price of the car is positively correlated with the safety rating of the car, and the fuel efficiency of the car is negatively correlated with the price of the car.
Step 2: Represent the problem in a logical form.
This could be done using a variety of formalisms, such as First Order Predicate Calculus (FOPC), propositional logic, or decision trees. For example, the problem statement "I am trying to decide which car to buy" could be represented in FOPC as follows:
∃x (Car(x) AND Price(x) < $20,000 AND FuelEfficiency(x) > 30 mpg AND SafetyRating(x) > 5 AND Features(x) = {sunroof, air conditioning, power windows})
This FOPC expression states that there exists a car that costs less than $20,000, has a fuel efficiency of greater than 30 mpg, has a safety rating of greater than 5, and has the specified features.
Step 3: Reason about the problem to identify potential solutions.
This involves using the logical representation of the problem to draw inferences and identify possible solutions. For example, given the FOPC expression above, we could infer that the following cars are potential solutions:
Toyota Corolla
Honda Civic
Hyundai Elantra
Kia Forte
Step 4: Evaluate the potential solutions to select the best one.
This could involve considering a variety of factors, such as the likelihood of success, the cost of implementation, and the potential risks. For example, we could evaluate the potential solutions based on the following factors:
Price: The Toyota Corolla is the least expensive car of the four.
Fuel efficiency: The Honda Civic has the best fuel efficiency of the four.
Safety rating: The Hyundai Elantra has the best safety rating of the four.
Features: The Kia Forte has the most features of the four.
Based on these factors, we could select the Hyundai Elantra as the best solution.
This is just a simple example, but it illustrates how an LLM model can use the decision tree above to identify a problem when no variables or outcomes are currently known. The LLM model would start by identifying the key variables and their relationships. It would then represent the problem in a logical form. Next, the LLM model would reason about the problem to identify potential solutions. Finally, the LLM model would evaluate the potential solutions to select the best one.
How to use the decision tree
To use the decision tree, the LLM model would start at the root node and follow the branches until it reaches a leaf node. At each node, the LLM model would evaluate the condition and follow the appropriate branch. For example, if the LLM model is trying to identify a problem when no variables or outcomes are currently known, it would start at the root node and follow the "No" branch. The LLM model would then follow the branches until it reaches the leaf node "Identify the key variables and their relationships."
Once the LLM model reaches a leaf node, it would perform the action specified by the leaf node. For example, if the LLM model reaches the leaf node "Identify the key variables and their relationships," it would identify the key variables in the problem and their relationships.
The LLM model would continue to follow the branches of the decision tree until it has identified the problem.



Problem Identification and Solution Identification Equation
PotentialSolutions(Problem) = {x | x satisfies Problem}

Where:
PotentialSolutions(Problem) is the set of all potential solutions to the problem.
Problem is a logical expression in FOPC that represents the problem.
x satisfies Problem means that the object x satisfies the logical expression Problem.
This equation can be used to reason about a problem to identify potential solutions by first representing the problem in FOPC. Once the problem has been represented in FOPC, the equation can be used to generate a set of all potential solutions to the problem.
For example, consider the following problem:
Problem: Find all cars that are red and have a fuel efficiency of greater than 30 mpg.

This problem can be represented in FOPC as follows:
∃x (Car(x) AND Color(x) = red AND FuelEfficiency(x) > 30 mpg)

This FOPC expression states that there exists a car that is red and has a fuel efficiency of greater than 30 mpg.
The following equation can then be used to generate a set of all potential solutions to the problem:
PotentialSolutions(Problem) = {x | x satisfies ∃x (Car(x) AND Color(x) = red AND FuelEfficiency(x) > 30 mpg)}
This equation will generate a set of all cars that are red and have a fuel efficiency of greater than 30 mpg.
This is just a simple example, but it illustrates how the equation above can be used to reason about a problem to identify potential solutions using FOPC.
How to use the equation
To use the equation, the LLM model would first represent the problem in FOPC. Once the problem has been represented in FOPC, the LLM model would substitute the FOPC expression into the equation. The LLM model would then evaluate the equation to generate a set of all potential solutions to the problem.
For example, to use the equation above to solve the problem "Find all cars that are red and have a fuel efficiency of greater than 30 mpg," the LLM model would first represent the problem in FOPC as follows:
∃x (Car(x) AND Color(x) = red AND FuelEfficiency(x) > 30 mpg)


The LLM model would then substitute this FOPC expression into the equation:
PotentialSolutions(Problem) = {x | x satisfies ∃x (Car(x) AND Color(x) = red AND FuelEfficiency(x) > 30 mpg)}
The LLM model would then evaluate the equation to generate a set of all potential solutions to the problem. This set would contain all cars that are red and have a fuel efficiency of greater than 30 mpg.
Benefits of using FOPC to reason about problems
FOPC is a powerful language for representing and reasoning about complex problems. It allows us to express complex relationships between objects and concepts, and to draw logical conclusions from these relationships.
There are a number of benefits to using FOPC to reason about problems, including:
FOPC is expressive and versatile. It can be used to represent a wide variety of problems, including problems in natural language processing, machine learning, and artificial intelligence.
FOPC is formal and rigorous. This makes it possible to develop sound and complete reasoning algorithms.
FOPC is efficient. There are a number of efficient algorithms for reasoning about FOPC expressions.
Conclusion
The equation above can be used to reason about a problem to identify potential solutions using FOPC. This equation is based on the idea that the set of all potential solutions to a problem is the set of all objects that satisfy the logical expression that represents the problem.

Creating Sub Problems When Faced With Unsolvable Problems Equation
Subproblems(Problem) = {x | x is a subproblem of Problem}

Where:
Subproblems(Problem) is the set of all subproblems of the problem.
Problem is a logical expression in First Order Predicate Calculus (FOPC) that represents the problem.
x is a subproblem of Problem means that the problem x is a part of the problem Problem.
This equation can be used to generate smaller, subproblems, based on a larger and unsolvable problem by first representing the larger problem in FOPC. Once the larger problem has been represented in FOPC, the equation can be used to generate a set of all subproblems of the larger problem.
For example, consider the following problem:
Problem: Find all cars that are red and have a fuel efficiency of greater than 30 mpg.

This problem can be represented in FOPC as follows:
∃x (Car(x) AND Color(x) = red AND FuelEfficiency(x) > 30 mpg)

This FOPC expression states that there exists a car that is red and has a fuel efficiency of greater than 30 mpg.
The following equation can then be used to generate a set of all subproblems of the larger problem:
Subproblems(Problem) = {x | x is a subproblem of ∃x (Car(x) AND Color(x) = red AND FuelEfficiency(x) > 30 mpg)}
This equation will generate a set of subproblems, such as:
Find all cars that are red.
Find all cars that have a fuel efficiency of greater than 30 mpg.
Find all cars that are red and have a fuel efficiency of greater than 20 mpg.
These subproblems are smaller and more manageable than the original problem. They can also be solved independently of each other.
This is just a simple example, but it illustrates how the equation above can be used to generate smaller, subproblems, based on a larger and unsolvable problem.
How to use the equation
To use the equation, the LLM model would first represent the larger problem in FOPC. Once the larger problem has been represented in FOPC, the LLM model would substitute the FOPC expression into the equation. The LLM model would then evaluate the equation to generate a set of all subproblems of the larger problem.

Benefits of using FOPC to generate subproblems
FOPC is a powerful language for representing and reasoning about complex problems. It allows us to express complex relationships between objects and concepts, and to draw logical conclusions from these relationships.
There are a number of benefits to using FOPC to generate subproblems, including:
FOPC is expressive and versatile. It can be used to represent a wide variety of problems, including problems in natural language processing, machine learning, and artificial intelligence.
FOPC is formal and rigorous. This makes it possible to develop sound and complete algorithms for generating subproblems.
FOPC is efficient. There are a number of efficient algorithms for generating subproblems from FOPC expressions.
Conclusion
The equation above can be used to generate smaller, subproblems, based on a larger and unsolvable problem using First Order Predicate Calculus (FOPC). This equation is based on the idea that the set of all subproblems of a problem is the set of all objects that are parts of the problem.
FOPC is a powerful language for representing and reasoning about complex problems. There are a number of benefits to using FOPC to generate subproblems, including its expressiveness, formality, and efficiency.


Putting This All Together:
Algorithm: Hybrid Logical Problem Solving Algorithm (HLPSA)
Input: 
- Problem statement P
- Background knowledge BK (set of logical axioms and facts representing knowledge about the domain)
Output: Set of solutions or subproblems S
1. Represent the problem P as a logical expression Lp in First Order Predicate Calculus using the background knowledge BK
2. If Lp is solvable:
2.1 Apply the Problem Identification and Solution Identification Equation: S = {x | x satisfies Lp} 
2.2 Return S
3. If Lp is not solvable: 
3.1 Apply the Creating Sub Problems When Faced With Unsolvable Problems Equation: Sp = {x | x is a subproblem of Lp}
3.2 For each subproblem s in Sp:
3.2.1 Solve s using the LLM Fallback Algorithm with the background knowledge BK to generate a set of possible solutions/outcomes Os 
3.2.2 Add Os to S
3.3 Return S
This algorithm first attempts to directly solve the problem P by representing it in FOPC and identifying potential solutions using the Problem Identification and Solution Identification Equation. 
If P is not directly solvable, the algorithm breaks it down into subproblems using the Creating Sub Problems When Faced With Unsolvable Problems Equation. It then solves each subproblem using the LLM Fallback Algorithm to generate possible solutions/outcomes. 
The solutions/outcomes from all subproblems are aggregated and returned.
The key steps utilizing FOPC are:
- Representing the original problem P as a logical expression Lp using predicates and terms from the background knowledge BK
- Generating subproblems Sp by identifying logical subsets and components of Lp
- Formulating queries for the LLM Fallback Algorithm using Lp and BK

This allows the problem solving process to leverage the expressiveness and logic of FOPC.
Sure, I can try to explain how the algorithm works in more detail.
The algorithm is based on the idea of using First Order Predicate Calculus (FOPC) to represent and solve problems in a logical and systematic way. FOPC is a language that allows us to express complex statements using variables, constants, predicates, functions, quantifiers, and logical connectives. For example, we can use FOPC to say something like:
(∀x)(∀y)(above(x,y) ⇔ (on(x,y) ∨ (∃z)(on(x,z) ∧ above(z,y))))
This means that for any objects x and y, x is above y if and only if x is on y or there exists some object z such that x is on z and z is above y.
The algorithm takes a problem statement P and some background knowledge BK as input. The background knowledge BK is a set of logical axioms and facts that represent the domain of the problem. For example, if the problem is about blocks on a table, the background knowledge might include facts like:
on(a,b) on(b,c) on(c,table) color(a,red) color(b,green) color(c,blue)
The algorithm then tries to represent the problem P as a logical expression Lp using the predicates and terms from the background knowledge BK. For example, if the problem is to find all the blocks that are above the table, the logical expression Lp might be:
(∃x)(above(x,table))
This means that there exists some object x such that x is above the table.
The algorithm then checks if Lp is solvable. This means that there is a way to assign values to the variables in Lp such that Lp becomes true. For example, in the above case, Lp is solvable because we can assign x to a, b, or c and make Lp true.
If Lp is solvable, the algorithm applies the Problem Identification and Solution Identification Equation to find all the possible solutions. This equation is:
S = {x | x satisfies Lp}
This means that the set of solutions S is the set of all values of x that make Lp true. For example, in the above case, S would be:
S = {a,b,c}
This means that a, b, and c are all solutions to the problem.
If Lp is not solvable, the algorithm applies the Creating Sub Problems When Faced With Unsolvable Problems Equation to generate subproblems. This equation is:
Sp = {x | x is a subproblem of Lp}
This means that the set of subproblems Sp is the set of all expressions x that are logically related to Lp but simpler or more specific. For example, if Lp is:
(∀x)(∀y)(above(x,y) ⇒ color(x,yellow))
This means that for any objects x and y, if x is above y then x has the same color as y. This expression is not solvable because there are no yellow blocks in our domain.
A possible subproblem of Lp might be:
(∃x)(∃y)(above(x,y) ∧ color(x,yellow))
This means that there exists some objects x and y such that x is above y and x has the same color as y. This expression is simpler than Lp because it uses existential quantifiers instead of universal quantifiers. It is also more specific than Lp because it adds a condition on the color of x.
The algorithm then solves each subproblem s in Sp using the LLM Fallback Algorithm with the background knowledge BK. The LLM Fallback Algorithm is a method for finding possible solutions or outcomes for a logical query using inference rules and heuristics. For example, if s is:
(∃x)(∃y)(above(x,y) ∧ color(x,yellow))
The LLM Fallback Algorithm might use the following steps to find possible solutions or outcomes:
Use Modus Ponens to infer new facts from existing facts and axioms
Use Existential Instantiation to replace existential variables with constants
Use Unification to match terms and predicates
Use Resolution to eliminate contradictory clauses
Use Heuristics to guide the search process
Using these steps, the LLM Fallback Algorithm might generate a set of possible solutions or outcomes Os for s such as:
Os = {no solution}
This means that there is no solution for s because there are no yellow blocks in our domain.
The algorithm then adds Os to S for each subproblem s in Sp. The final set of solutions or subproblems S is then returned as output.
The algorithm uses FOPC to leverage the expressiveness and logic of this language. By representing problems and subproblems in FOPC, the algorithm can use logical rules and methods to find solutions or outcomes in a systematic way. The algorithm also uses FOPC to formulate queries for the LLM Fallback Algorithm using Lp and BK. This allows the algorithm to use the background knowledge BK to guide the search process and infer new information.
